#!/usr/bin/env node

/**
 * Enhanced Type Duplication Checker with Auto-Generated Type Filtering
 *
 * USAGE:
 *   node scripts/check-type-duplicates.cjs                          # Full analysis
 *   node scripts/check-type-duplicates.cjs --pre-commit             # Pre-commit check (fails if duplications found)
 *   node scripts/check-type-duplicates.cjs --show-ignored           # Show ignored auto-generated types
 *   node scripts/check-type-duplicates.cjs --show-legitimate        # Show legitimate duplications only
 *   node scripts/check-type-duplicates.cjs --add-ignore=TypeName    # Get command to add type to ignore list
 *   node scripts/check-type-duplicates.cjs --add-legitimate=TypeName # Add type to legitimate duplications
 *   node scripts/check-type-duplicates.cjs --init-config            # Create .duplication-lint.json config file
 *
 * FEATURES:
 *   âœ… Filters out auto-generated types (Supabase, database.types.ts, etc.)
 *   âœ… Linting system for marking legitimate duplications as OK
 *   âœ… Shows real duplications that need fixing
 *   âœ… Provides sed commands for bulk fixes
 *   âœ… Tracks imports to show what needs updating
 *   âœ… Configurable ignore lists for different environments
 *   âœ… Inline comment support: // duplication-ignore
 *   âœ… Pattern-based rules for family components and utilities
 *   âœ… Environment bypass via .code.env file
 *
 * IGNORE PATTERNS:
 *   Files: database.types.ts, *.generated.ts, test files
 *   Types: Json, Database, Tables, Views, Functions, Enums, etc.
 */

const fs = require('node:fs');
const path = require('node:path');
const { execSync } = require('node:child_process');

// Load configuration from YAML file
function loadConfiguration() {
  try {
    // Try to load YAML configuration
    const yaml = require('js-yaml');
    const configPath = path.join(process.cwd(), 'supernal.yaml');

    if (fs.existsSync(configPath)) {
      const configContent = fs.readFileSync(configPath, 'utf8');
      const config = yaml.load(configContent);

      if (config.type_duplication?.enabled) {
        const yamlConfig = {
          searchDirs: config.type_duplication.scan_directories || [],
          excludeDirs: config.type_duplication.exclude_directories || [],
          reportDirectory:
            config.type_duplication.report_directory || 'reports/duplications',
          ignorePatterns: config.type_duplication.ignore_patterns || [],
          preCommitHook: config.type_duplication.pre_commit_hook !== false,
          blockCommits:
            config.type_duplication.block_commits_on_duplications !== false,
          allowForce: config.type_duplication.allow_force_commits !== false,
          ignoreAutoGenerated:
            config.type_duplication.ignore_auto_generated !== false,
          analysisTimeout:
            config.type_duplication.analysis_timeout_seconds || 30,
          incrementalUpdates:
            config.type_duplication.incremental_updates !== false,
        };

        // Add missing arrays that are expected by the code
        return addMissingConfigArrays(yamlConfig);
      }
    }
  } catch (error) {
    console.warn(
      `Warning: Could not load YAML configuration: ${error.message}`
    );
  }

  // Fallback to default configuration
  return getDefaultConfiguration();
}

function addMissingConfigArrays(config) {
  // Add missing arrays that are expected by the code but not in YAML config
  return {
    ...config,
    // File patterns for inclusion/exclusion
    includePatterns: [/\.(ts|tsx|js|jsx)$/],
    excludePatterns: [
      /node_modules/,
      /\.git/,
      /dist/,
      /build/,
      /coverage/,
      /\.next/,
      /\.nuxt/,
      /test-results/,
      /playwright-report/,
    ],
    // Files to ignore (beyond patterns)
    ignoreFiles: ['database.types.ts', 'generated.ts', '.d.ts'],
    // Type names to ignore
    ignoreTypeNames: [
      'Database',
      'Tables',
      'Enums',
      'Json',
      /^Database\w*/,
      /^Supabase\w*/,
      /Generated$/,
    ],
  };
}

function getDefaultConfiguration() {
  const baseConfig = {
    searchDirs: [
      'src',
      'lib',
      'components',
      'pages',
      'utils',
      'services',
      'types',
    ],
    excludeDirs: [
      'node_modules',
      'dist',
      'build',
      '.git',
      'archive',
      'test-results',
      'playwright-report',
      'temp-user-data',
      'coverage',
      '.next',
      '.nuxt',
      'temp',
      'tmp',
    ],
    reportDirectory: 'reports/duplications',
    ignorePatterns: ['*.generated.ts', '*.d.ts', 'database.types.ts'],
    preCommitHook: true,
    blockCommits: true,
    allowForce: true,
    ignoreAutoGenerated: true,
    analysisTimeout: 30,
    incrementalUpdates: true,
  };

  return addMissingConfigArrays(baseConfig);
}

// Load configuration at startup
const CONFIG = loadConfiguration();

// Legacy configuration for backward compatibility
const _LEGACY_CONFIG = {
  // Directories to search
  searchDirs: CONFIG.searchDirs,

  // Directories to exclude
  excludeDirs: CONFIG.excludeDirs,

  // File patterns to include
  includePatterns: [/\.ts$/, /\.tsx$/, /\.js$/, /\.jsx$/],

  // File patterns to exclude
  excludePatterns: [
    /\.test\./,
    /\.spec\./,
    /\.stories\./,
    /\.d\.ts$/,
    /node_modules/,
    /dist\//,
    /build\//,
  ],

  // IGNORE LISTS for auto-generated and legitimate duplications
  ignoreFiles: [
    // Supabase auto-generated files
    /\/database\.types\.ts$/,
    /\/supabase\.ts$/,
    /\/database-enhanced\.ts$/,
    /\/types_db.*\.ts$/,
    /\/database\.generated\.ts$/,

    // Other auto-generated patterns
    /\.generated\.ts$/,
    /\.auto\.ts$/,
    /\/generated\//,
    /\/auto-generated\//,

    // Test and mock files (often have legitimate duplicates)
    /\.test\.ts$/,
    /\.spec\.ts$/,
    /\/test\//,
    /\/tests\//,
    /\/mock/,
    /\/fixtures\//,

    // Temporary and backup files
    /\.backup\.ts$/,
    /\.tmp\.ts$/,
    /\/temp\//,
  ],

  ignoreTypeNames: [
    // Auto-generated Supabase types
    'Json',
    'Database',
    'Tables',
    'Views',
    'Functions',
    'Enums',
    'CompositeTypes',

    // Common auto-generated patterns
    /^DB[A-Z]/, // DB-prefixed types
    /^Generated[A-Z]/, // Generated-prefixed types
    /^Auto[A-Z]/, // Auto-prefixed types
    /Schema$/, // Schema-suffixed types
    /Types?$/, // Types/Type suffixed

    // Development/environment types that might be duplicated legitimately
    'isDevelopment',
    'isProduction',
    'isTest',
    'Environment',
    'Config',
    'Settings',
  ],
};

// Add after the CONFIG section (around line 150), before EXPORT_PATTERNS
const DUPLICATION_LINTING = {
  // Configuration file path
  configFile: '.duplication-lint.json',

  // ESLint-style comment patterns for duplication control
  eslintStylePatterns: {
    // Complete ignore patterns (hidden from reports)
    ignore: [
      /\/\/\s*eslint-disable-next-line\s+duplication\/legitimate/i,
      /\/\/\s*eslint-disable\s+duplication\/legitimate/i,
      /\/\*\s*eslint-disable\s+duplication\/legitimate\s*\*\//i,
      /\/\/\s*duplication-ignore/i,
      /\/\*\s*duplication-ignore\s*\*\//i,
      /\/\/\s*@duplication-ignore/i,
      /\/\*\s*@duplication-ignore\s*\*\//i,
    ],

    // Warning patterns (concerning but not blocking)
    warning: [
      /\/\/\s*eslint-disable-next-line\s+duplication\/concerning/i,
      /\/\/\s*eslint-disable\s+duplication\/concerning/i,
      /\/\*\s*eslint-disable\s+duplication\/concerning\s*\*\//i,
      /\/\/\s*duplication-warning/i,
      /\/\*\s*duplication-warning\s*\*\//i,
      /\/\/\s*@duplication-warning/i,
      /\/\*\s*@duplication-warning\s*\*\//i,
    ],

    // Family-specific patterns (legitimate across family boundaries)
    familyLegitimate: [
      /\/\/\s*eslint-disable-next-line\s+duplication\/family-component/i,
      /\/\/\s*eslint-disable\s+duplication\/family-component/i,
      /\/\*\s*eslint-disable\s+duplication\/family-component\s*\*\//i,
      /\/\/\s*duplication-family-ok/i,
      /\/\*\s*duplication-family-ok\s*\*\//i,
    ],
  },

  // Default legitimate duplication patterns
  defaultLegitimatePatterns: {
    // Family-specific components that are OK to duplicate
    familyComponents: [
      'HeroSection',
      'Header',
      'Footer',
      'Layout',
      'Navigation',
      'Sidebar',
      'MainContent',
      'AboutSection',
      'ContactForm',
      'FeatureCard',
      'TestimonialCard',
      'PricingCard',
    ],

    // Cross-family utilities that are OK to duplicate
    utilityPatterns: [
      /^use[A-Z]/, // React hooks (useAuth in different contexts)
      /^create[A-Z]/, // Factory functions (createClient for different services)
      /^get[A-Z]/, // Getter functions (getEnvironment in different contexts)
      /^format[A-Z]/, // Formatter functions
      /^validate[A-Z]/, // Validation functions
      /^normalize[A-Z]/, // Normalization functions
      'cn', // Tailwind className utility
      'clsx', // Class name utility
      'metadata', // Next.js metadata (different per app)
    ],

    // Development/test utilities
    testPatterns: [
      /Test$/,
      /Mock$/,
      /Fixture$/,
      /Stub$/,
      'logger', // Different loggers per service
    ],

    // Configuration objects
    configPatterns: ['config', 'settings', 'options', 'constants'],
  },
};

// Enhanced regex patterns for finding exports (ACTUAL DEFINITIONS ONLY)
const EXPORT_PATTERNS = {
  // Type and interface exports (actual definitions only)
  interface: /export\s+interface\s+(\w+)/g,
  type: /export\s+type\s+(\w+)\s*=/g, // Only type aliases with =

  // Function exports (actual definitions only)
  function: /export\s+function\s+(\w+)/g,
  constFunction: /export\s+const\s+(\w+)\s*=\s*\(/g,
  arrowFunction: /export\s+const\s+(\w+)\s*=\s*[^=]*=>/g,

  // Enum exports (actual definitions only)
  enum: /export\s+enum\s+(\w+)/g,
  constEnum: /export\s+const\s+enum\s+(\w+)/g,

  // Constant exports (actual definitions only)
  const: /export\s+const\s+(\w+)(?!\s*=\s*[([])/g, // const but not function/array

  // Class exports (actual definitions only)
  class: /export\s+class\s+(\w+)/g,

  // Default exports with names (actual definitions only)
  defaultClass: /export\s+default\s+class\s+(\w+)/g,
  defaultFunction: /export\s+default\s+function\s+(\w+)/g,

  // REMOVED: Re-export patterns that were causing false positives:
  // - export { Name } from 'module'
  // - export { Name }
  // - export * from 'module'
  // These are legitimate architectural patterns, not duplications
};

// Import tracking patterns to find where duplicated exports are being used
const IMPORT_PATTERNS = {
  // Named imports: import { name } from 'package'
  namedImport: /import\s*{[^}]*\b(\w+)\b[^}]*}\s*from\s*['"`]([^'"`]+)['"`]/g,

  // Namespace imports: import * as name from 'package'
  namespaceImport: /import\s*\*\s*as\s+(\w+)\s*from\s*['"`]([^'"`]+)['"`]/g,

  // Default imports: import name from 'package'
  defaultImport: /import\s+(\w+)\s*from\s*['"`]([^'"`]+)['"`]/g,

  // Mixed imports: import name, { other } from 'package'
  mixedImport: /import\s+(\w+)\s*,\s*{[^}]*}\s*from\s*['"`]([^'"`]+)['"`]/g,

  // Re-exports: export { name } from 'package'
  reExport: /export\s*{[^}]*\b(\w+)\b[^}]*}\s*from\s*['"`]([^'"`]+)['"`]/g,

  // Dynamic imports: import('package').then() or await import('package')
  dynamicImport: /import\s*\(\s*['"`]([^'"`]+)['"`]\s*\)/g,
};

function shouldIgnoreFile(filePath) {
  return CONFIG.ignoreFiles.some((pattern) => {
    if (pattern instanceof RegExp) {
      return pattern.test(filePath);
    }
    return filePath.includes(pattern);
  });
}

function shouldIgnoreTypeName(typeName) {
  return CONFIG.ignoreTypeNames.some((pattern) => {
    if (pattern instanceof RegExp) {
      return pattern.test(typeName);
    }
    return typeName === pattern;
  });
}

function shouldIncludeFile(filePath) {
  return CONFIG.includePatterns.some((pattern) => pattern.test(filePath));
}

function shouldExcludeFile(filePath) {
  return (
    CONFIG.excludePatterns.some((pattern) => pattern.test(filePath)) ||
    shouldIgnoreFile(filePath)
  );
}

function findExportsInFile(filePath) {
  try {
    const content = fs.readFileSync(filePath, 'utf8');
    const exports = [];
    const seenExports = new Map(); // Track exports by name+line to prevent duplicates

    // Find all export types
    for (const [exportType, pattern] of Object.entries(EXPORT_PATTERNS)) {
      let match;
      const globalPattern = new RegExp(pattern.source, 'g');

      while ((match = globalPattern.exec(content)) !== null) {
        const name = match[1];
        const line = content.substring(0, match.index).split('\n').length;
        const key = `${name}:${line}`; // Unique key for name+line combination

        // Check if we've already seen this export (same name, same line)
        if (seenExports.has(key)) {
          // Skip this duplicate, but prefer more specific patterns over generic ones
          const existing = seenExports.get(key);

          // Priority order: arrowFunction > constFunction > const
          // (more specific patterns win)
          if (
            exportType === 'arrowFunction' &&
            existing.type === 'constFunction'
          ) {
            // Replace constFunction with arrowFunction (more specific)
            const existingIndex = exports.indexOf(existing);
            if (existingIndex !== -1) {
              exports[existingIndex] = {
                name,
                type: exportType,
                line,
                match: match[0],
              };
              seenExports.set(key, exports[existingIndex]);
            }
          } else if (
            exportType === 'constFunction' &&
            existing.type === 'const'
          ) {
            // Replace const with constFunction (more specific)
            const existingIndex = exports.indexOf(existing);
            if (existingIndex !== -1) {
              exports[existingIndex] = {
                name,
                type: exportType,
                line,
                match: match[0],
              };
              seenExports.set(key, exports[existingIndex]);
            }
          }
          // Skip if we already have a more specific pattern
          continue;
        }

        // Add new export
        const exportData = {
          name,
          type: exportType,
          line,
          match: match[0],
        };

        exports.push(exportData);
        seenExports.set(key, exportData);
      }
    }

    return exports;
  } catch (error) {
    console.warn(`Warning: Could not read file ${filePath}: ${error.message}`);
    return [];
  }
}

function findImportsInFile(filePath) {
  try {
    const content = fs.readFileSync(filePath, 'utf8');
    const imports = [];

    // Find all import types
    for (const [importType, pattern] of Object.entries(IMPORT_PATTERNS)) {
      let match;
      const globalPattern = new RegExp(pattern.source, 'g');

      while ((match = globalPattern.exec(content)) !== null) {
        if (importType === 'dynamicImport') {
          // Dynamic imports only have package info, no specific names
          imports.push({
            name: null,
            type: importType,
            from: match[1],
            line: content.substring(0, match.index).split('\n').length,
            match: match[0],
          });
        } else {
          // Regular imports have both name and package
          imports.push({
            name: match[1],
            type: importType,
            from: match[2],
            line: content.substring(0, match.index).split('\n').length,
            match: match[0],
          });
        }
      }
    }

    return imports;
  } catch (error) {
    console.warn(`Warning: Could not read file ${filePath}: ${error.message}`);
    return [];
  }
}

function findAllExports() {
  const allExports = {}; // { filePath: [exportData...] }
  const allImports = {}; // Track imports for cross-referencing
  const fileCount = { total: 0, processed: 0 };

  function scanDirectory(dir) {
    try {
      const items = fs.readdirSync(dir);

      for (const item of items) {
        const fullPath = path.join(dir, item);
        const stat = fs.statSync(fullPath);

        if (stat.isDirectory()) {
          if (!CONFIG.excludeDirs.includes(item)) {
            scanDirectory(fullPath);
          }
        } else if (stat.isFile()) {
          fileCount.total++;

          if (shouldIncludeFile(fullPath) && !shouldExcludeFile(fullPath)) {
            fileCount.processed++;

            // Collect exports for this file
            const exports = findExportsInFile(fullPath);
            if (exports.length > 0) {
              allExports[fullPath] = exports;
            }

            // Collect imports for this file
            const imports = findImportsInFile(fullPath);
            for (const importData of imports) {
              const name = importData.name;
              if (!allImports[name]) {
                allImports[name] = [];
              }
              allImports[name].push({
                file: fullPath,
                line: importData.line,
                type: importData.type,
                from: importData.from,
                match: importData.match,
              });
            }
          }
        }
      }
    } catch (error) {
      console.warn(
        `Warning: Could not scan directory ${dir}: ${error.message}`
      );
    }
  }

  // Scan all configured directories
  const scanDirs = CONFIG.searchDirs;
  for (const scanDir of scanDirs) {
    console.log(`ðŸ” Scanning ${scanDir}...`);
    scanDirectory(scanDir);
  }

  console.log(
    `ðŸ“Š Processed ${fileCount.processed} files (${fileCount.total} total)`
  );

  return { exports: allExports, imports: allImports };
}

function analyzeExports(allExports) {
  const duplicates = {};
  const ignored = {};
  const legitimateDuplicates = {}; // NEW: for linting-approved duplications
  const warningDuplicates = {}; // NEW: concerning but not blocking
  const familyLegitimate = {}; // NEW: family-specific components
  const stats = {
    totalExports: 0,
    uniqueNames: 0,
    duplicateNames: 0,
    duplicateInstances: 0,
    ignoredNames: 0,
    ignoredInstances: 0,
    legitimateNames: 0, // NEW
    legitimateInstances: 0, // NEW
    warningNames: 0, // NEW: concerning duplications
    warningInstances: 0, // NEW
    familyLegitimateNames: 0, // NEW: family components
    familyLegitimateInstances: 0, // NEW
    typeBreakdown: {},
  };

  // Load linting configuration
  const lintConfig = loadDuplicationLintConfig();

  // Group exports by name
  const exportsByName = {};
  for (const [filePath, exports] of Object.entries(allExports)) {
    for (const exportData of exports) {
      const name = exportData.name;

      if (!exportsByName[name]) {
        exportsByName[name] = [];
      }

      exportsByName[name].push({
        file: filePath,
        line: exportData.line,
        type: exportData.type,
        match: exportData.match,
      });
    }
  }

  // Count statistics and filter ignored types
  stats.totalExports = Object.values(allExports).reduce(
    (total, exports) => total + exports.length,
    0
  );
  stats.uniqueNames = Object.keys(exportsByName).length;

  // Separate duplicates from ignored types and legitimate duplications
  for (const [name, locations] of Object.entries(exportsByName)) {
    stats.typeBreakdown[locations[0].type] =
      (stats.typeBreakdown[locations[0].type] || 0) + 1;

    if (locations.length > 1) {
      // First check auto-generated types (original ignore logic)
      if (shouldIgnoreTypeName(name)) {
        // Type is auto-generated/legitimately duplicated (Supabase, etc.)
        ignored[name] = locations;
        stats.ignoredNames++;
        stats.ignoredInstances += locations.length;
      } else {
        // Check for ESLint-style inline comments first (highest priority)
        let commentClassification = null;
        let commentReason = null;
        let commentLine = null;

        for (const location of locations) {
          const inlineComment = checkInlineComment(
            location.file,
            location.line
          );
          if (inlineComment.type) {
            commentClassification = inlineComment.type;
            commentReason = inlineComment.reason || 'Marked via inline comment';
            commentLine = inlineComment.line;
            break; // Use first comment found
          }
        }

        if (commentClassification === 'ignore') {
          // Type is explicitly ignored via comment
          legitimateDuplicates[name] = {
            locations,
            reason: `Inline comment: ${commentReason} (line ${commentLine})`,
          };
          stats.legitimateNames++;
          stats.legitimateInstances += locations.length;
        } else if (commentClassification === 'warning') {
          // Type is concerning but not blocking
          warningDuplicates[name] = {
            locations,
            reason: `Warning: ${commentReason} (line ${commentLine})`,
          };
          stats.warningNames++;
          stats.warningInstances += locations.length;
        } else if (commentClassification === 'familyLegitimate') {
          // Type is legitimate family-specific component
          familyLegitimate[name] = {
            locations,
            reason: `Family component: ${commentReason} (line ${commentLine})`,
          };
          stats.familyLegitimateNames++;
          stats.familyLegitimateInstances += locations.length;
        } else {
          // Check configuration-based linting rules
          const lintResult = shouldIgnoreDuplication(
            name,
            locations,
            lintConfig
          );

          if (lintResult.ignored) {
            // Type is marked as legitimate duplication via linting config
            legitimateDuplicates[name] = {
              locations,
              reason: lintResult.reason,
            };
            stats.legitimateNames++;
            stats.legitimateInstances += locations.length;
          } else {
            // Type is a real duplication that needs attention
            duplicates[name] = locations;
            stats.duplicateNames++;
            stats.duplicateInstances += locations.length;
          }
        }
      }
    }
  }

  return {
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    stats,
  };
}

function generateFixCommands(duplicates) {
  const commands = [];

  // Group duplicates by common patterns
  const highPriorityDuplicates = Object.entries(duplicates)
    .filter(([_name, locations]) => locations.length >= 3)
    .sort(([, a], [, b]) => b.length - a.length)
    .slice(0, 10);

  if (highPriorityDuplicates.length === 0) {
    return ['# No high-priority duplications found (3+ definitions)'];
  }

  commands.push('# ðŸ› ï¸ TYPE CONSOLIDATION COMMANDS');
  commands.push(
    '# These are GENERIC PATTERNS - you decide WHERE to apply them'
  );
  commands.push('');

  for (const [name, locations] of highPriorityDuplicates) {
    commands.push(`# â•â•â• ${name} (${locations.length} definitions) â•â•â•`);

    // Analyze the locations to provide targeted advice
    const hasTypeAlias = locations.some((loc) =>
      loc.match.includes(`type ${name} =`)
    );
    const hasInterface = locations.some((loc) =>
      loc.match.includes(`interface ${name}`)
    );
    const hasFunction = locations.some((loc) =>
      loc.match.includes(`function ${name}`)
    );

    if (hasTypeAlias && hasInterface) {
      commands.push('# ISSUE: Mixed type alias and interface definitions');
      commands.push(
        '# SOLUTION: Pick ONE canonical definition (interface recommended)'
      );
      commands.push(
        `# 1. Remove type aliases: sed -i "/export type ${name} =/d" <target-files>`
      );
      commands.push(
        `# 2. Keep only canonical interface: grep -l "interface ${name}" <files>`
      );
    } else if (hasFunction) {
      commands.push('# ISSUE: Function defined in multiple locations');
      commands.push('# SOLUTION: Move to single canonical location');
      commands.push(
        `# 1. Find all definitions: grep -r "function ${name}" . --include="*.ts"`
      );
      commands.push(
        `# 2. Choose canonical location (usually shared utilities)`
      );
      commands.push(`# 3. Remove others, update imports`);
    } else {
      commands.push('# ISSUE: Multiple definitions of same type/interface');
      commands.push('# SOLUTION: Consolidate to single canonical definition');
      commands.push(
        `# 1. Compare definitions: grep -A 10 "interface ${name}\\|type ${name}" <files>`
      );
      commands.push(`# 2. Pick most complete definition as canonical`);
      commands.push(`# 3. Remove duplicates from other files`);
    }

    commands.push('');
  }

  // Add generic consolidation patterns
  commands.push('# ðŸ”§ GENERIC CONSOLIDATION PATTERNS:');
  commands.push('');
  commands.push('# Find duplicate type definitions:');
  commands.push(
    '# grep -r "export type TYPENAME =" . --include="*.ts" | head -5'
  );
  commands.push('');
  commands.push('# Find duplicate interface definitions:');
  commands.push(
    '# grep -r "export interface TYPENAME" . --include="*.ts" | head -5'
  );
  commands.push('');
  commands.push('# Remove specific type definition:');
  commands.push('# sed -i "/export type TYPENAME =/d" path/to/file.ts');
  commands.push('');
  commands.push('# Remove specific interface definition (multi-line):');
  commands.push('# sed -i "/export interface TYPENAME/,/^}/d" path/to/file.ts');
  commands.push('');
  commands.push('# Update imports after removing definition:');
  commands.push(
    "# sed -i \"s|from './removed-source'|from './canonical-source'|g\" <target-files>"
  );

  return commands;
}

function _extractPackageName(filePath) {
  if (filePath.includes('@supernal-coding/types'))
    return '@supernal-coding/types';
  if (filePath.includes('@supernal-id/types')) return '@supernal-id/types';
  if (filePath.includes('platform/packages')) return 'platform-package';
  if (filePath.includes('platform/services')) return 'platform-service';
  if (filePath.includes('families/')) {
    const family = filePath.split('families/')[1].split('/')[0];
    return `family-${family}`;
  }
  return 'unknown';
}

function writeResultsToFiles(
  duplicates,
  ignored,
  legitimateDuplicates,
  warningDuplicates,
  familyLegitimate,
  stats,
  imports = {}
) {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19);
  const baseDir = `reports/duplications/${timestamp}`;

  // Ensure directories exist
  if (!fs.existsSync('reports/duplications')) {
    fs.mkdirSync('reports/duplications', { recursive: true });
  }
  if (!fs.existsSync(baseDir)) {
    fs.mkdirSync(baseDir, { recursive: true });
  }

  // Generate fix commands
  const fixCommands = generateFixCommands(duplicates);

  // Write individual duplication files
  const duplicationFiles = [];
  for (const [name, locations] of Object.entries(duplicates)) {
    const filename = `${name.replace(/[^a-zA-Z0-9]/g, '_')}.md`;
    const filePath = `${baseDir}/${filename}`;

    const content = generateDuplicationReport(
      name,
      locations,
      imports[name] || []
    );
    fs.writeFileSync(filePath, content);
    duplicationFiles.push({ name, filename, count: locations.length });
  }

  // Write ignored types file
  if (Object.keys(ignored).length > 0) {
    const ignoredContent = generateIgnoredTypesReport(ignored, stats);
    fs.writeFileSync(`${baseDir}/ignored-types.md`, ignoredContent);
  }

  // Write legitimate duplications file
  if (Object.keys(legitimateDuplicates).length > 0) {
    const legitimateContent = generateLegitimateTypesReport(
      legitimateDuplicates,
      stats
    );
    fs.writeFileSync(
      `${baseDir}/legitimate-duplications.md`,
      legitimateContent
    );
  }

  // Write warning duplications file
  if (Object.keys(warningDuplicates).length > 0) {
    const warningContent = generateWarningTypesReport(warningDuplicates, stats);
    fs.writeFileSync(`${baseDir}/warning-duplications.md`, warningContent);
  }

  // Write family legitimate duplications file
  if (Object.keys(familyLegitimate).length > 0) {
    const familyContent = generateFamilyLegitimateReport(
      familyLegitimate,
      stats
    );
    fs.writeFileSync(`${baseDir}/family-legitimate.md`, familyContent);
  }

  // Write summary index file
  const summaryContent = generateSummaryReport(
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    stats,
    duplicationFiles,
    timestamp
  );
  fs.writeFileSync(`${baseDir}/README.md`, summaryContent);

  // Write fix commands file
  if (fixCommands.length > 0) {
    const fixContent = `# Fix Commands\n\n\`\`\`bash\n${fixCommands.join('\n')}\n\`\`\`\n`;
    fs.writeFileSync(`${baseDir}/fix-commands.sh`, fixContent);
  }

  // Write JSON data for tools
  const jsonData = {
    timestamp: new Date().toISOString(),
    stats,
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    imports,
    fixCommands,
    duplicationFiles,
  };
  fs.writeFileSync(`${baseDir}/data.json`, JSON.stringify(jsonData, null, 2));

  // Create/update latest symlink
  const latestPath = 'reports/duplications/latest';
  if (fs.existsSync(latestPath)) {
    fs.unlinkSync(latestPath);
  }
  fs.symlinkSync(timestamp, latestPath);

  return {
    baseDir,
    summaryPath: `${baseDir}/README.md`,
    dataPath: `${baseDir}/data.json`,
    duplicationCount: duplicationFiles.length,
  };
}

function generateDuplicationReport(name, locations, imports) {
  let content = `# ${name} Duplication Report\n\n`;
  content += `**Duplication Count:** ${locations.length} definitions\n`;
  content += `**Import Usage:** ${imports.length} files\n\n`;

  // Add ESLint-style comment suggestions at the top
  content += generateESLintSuggestions(name, locations);
  content += `\n`;

  // Export locations
  content += `## ðŸ“¤ Export Locations\n\n`;
  for (const [index, location] of locations.entries()) {
    content += `### ${index + 1}. ${path.basename(location.file)}\n`;
    content += `- **File:** \`${location.file}:${location.line}\`\n`;
    content += `- **Type:** ${location.type}\n`;
    content += `- **Definition:**\n\`\`\`typescript\n${location.match}\n\`\`\`\n\n`;

    // Add file-specific ESLint command
    content += generateFileSpecificESLintCommand(location, name);
  }

  // Group imports by source package (for use in multiple sections)
  const importsByPackage = {};
  for (const imp of imports) {
    if (!importsByPackage[imp.from]) {
      importsByPackage[imp.from] = [];
    }
    importsByPackage[imp.from].push(imp);
  }

  // Import usage
  if (imports.length > 0) {
    content += `## ðŸ“¥ Import Usage (${imports.length} files)\n\n`;

    for (const [fromPackage, packageImports] of Object.entries(
      importsByPackage
    )) {
      content += `### From \`${fromPackage}\`\n\n`;
      for (const imp of packageImports) {
        content += `- \`${imp.file}:${imp.line}\`\n`;
        content += `  \`\`\`typescript\n  ${imp.match}\n  \`\`\`\n`;
      }
      content += `\n`;
    }
  }

  // Fix recommendations
  content += `## ðŸ”§ Fix Recommendations\n\n`;
  content += `### 1. Choose Canonical Location\n`;
  const platformLocs = locations.filter((loc) =>
    loc.file.includes('platform/')
  );
  const familyLocs = locations.filter((loc) => loc.file.includes('families/'));

  if (platformLocs.length > 0 && familyLocs.length > 0) {
    content += `- **Platform definitions:** ${platformLocs.length} (shared/infrastructure)\n`;
    content += `- **Family definitions:** ${familyLocs.length} (domain-specific)\n`;
    content += `- **Recommendation:** Keep family-specific in families, platform-level in platform\n\n`;
  } else if (locations.length > 1) {
    content += `- **Multiple definitions found in same scope**\n`;
    content += `- **Recommendation:** Choose most complete definition, remove others\n\n`;
  }

  content += `### 2. Remove Duplicate Definitions\n`;
  content += `\`\`\`bash\n`;
  for (const location of locations.slice(1)) {
    // Skip first (canonical)
    content += `# Remove from ${location.file}\n`;
    if (location.type === 'interface') {
      content += `sed -i '/export interface ${name}/,/^}/d' "${location.file}"\n`;
    } else if (location.type === 'type') {
      content += `sed -i '/export type ${name} =/d' "${location.file}"\n`;
    } else {
      content += `# Manual removal needed for ${location.type}\n`;
    }
  }
  content += `\`\`\`\n\n`;

  content += `### 3. Update Imports\n`;
  if (imports.length > 0) {
    const canonicalPackage = determineCanonicalPackage(name, locations);
    content += `\`\`\`bash\n`;
    content += `# Update all imports to use canonical package: ${canonicalPackage}\n`;
    for (const [fromPackage, _packageImports] of Object.entries(
      importsByPackage
    )) {
      if (fromPackage !== canonicalPackage) {
        content += `find . -name "*.ts" -o -name "*.tsx" | xargs sed -i "s|from '${fromPackage}'|from '${canonicalPackage}'|g"\n`;
      }
    }
    content += `\`\`\`\n`;
  }

  return content;
}

function generateIgnoredTypesReport(ignored, stats) {
  let content = `# Ignored Auto-Generated Types\n\n`;
  content += `**Total Ignored:** ${stats.ignoredNames} types (${stats.ignoredInstances} instances)\n\n`;
  content += `These types are legitimately duplicated (auto-generated) and safely ignored.\n\n`;

  const sortedIgnored = Object.entries(ignored).sort(
    ([, a], [, b]) => b.length - a.length
  );

  for (const [name, locations] of sortedIgnored) {
    content += `## ${name}\n`;
    content += `**Instances:** ${locations.length}\n\n`;

    const files = [...new Set(locations.map((loc) => path.basename(loc.file)))];
    content += `**Files:** ${files.join(', ')}\n\n`;

    for (const location of locations.slice(0, 3)) {
      // Show first 3
      content += `- \`${location.file}:${location.line}\` (${location.type})\n`;
    }
    if (locations.length > 3) {
      content += `- ... and ${locations.length - 3} more\n`;
    }
    content += `\n`;
  }

  return content;
}

function generateSummaryReport(
  duplicates,
  ignored,
  legitimateDuplicates,
  warningDuplicates,
  familyLegitimate,
  stats,
  duplicationFiles,
  timestamp
) {
  let content = `# Type Duplication Analysis Summary\n\n`;
  content += `**Generated:** ${new Date().toISOString()}\n`;
  content += `**Report ID:** ${timestamp}\n\n`;

  // Statistics
  content += `## ðŸ“Š Summary Statistics\n\n`;
  content += `- **Total Exports Found:** ${stats.totalExports}\n`;
  content += `- **ðŸš¨ Real Duplications:** ${stats.duplicateNames} names (${stats.duplicateInstances} instances)\n`;
  content += `- **âš ï¸ Warning Duplications:** ${stats.warningNames || 0} names (${stats.warningInstances || 0} instances) - concerning but not blocking\n`;
  content += `- **ðŸ‘¥ Family Components:** ${stats.familyLegitimateNames || 0} names (${stats.familyLegitimateInstances || 0} instances) - legitimate across families\n`;
  content += `- **ðŸ” Legitimate Duplications:** ${stats.legitimateNames} names (${stats.legitimateInstances} instances)\n`;
  content += `- **âœ… Ignored Auto-Generated:** ${stats.ignoredNames} names (${stats.ignoredInstances} instances)\n`;
  content += `- **Unique Export Names:** ${stats.uniqueNames}\n\n`;

  // Sort duplication files by count (for use throughout function)
  const sortedDupes = duplicationFiles.sort((a, b) => b.count - a.count);

  if (stats.duplicateNames === 0) {
    content += `## âœ… SUCCESS: No Real Duplications Found!\n\n`;
    content += `All real type duplications have been resolved.\n\n`;
  } else {
    // Top duplications
    content += `## ðŸš¨ Top Duplications (by count)\n\n`;

    for (const dupe of sortedDupes.slice(0, 15)) {
      content += `- **[${dupe.name}](${dupe.filename})**: ${dupe.count} definitions\n`;
    }
    if (sortedDupes.length > 15) {
      content += `- ... and ${sortedDupes.length - 15} more\n`;
    }
    content += `\n`;
  }

  // Legitimate duplications section
  if (Object.keys(legitimateDuplicates).length > 0) {
    content += `## ðŸ” Legitimate Duplications (marked as OK)\n\n`;

    const sortedLegitimate = Object.entries(legitimateDuplicates)
      .sort(([, a], [, b]) => b.locations.length - a.locations.length)
      .slice(0, 10);

    for (const [name, { locations, reason }] of sortedLegitimate) {
      content += `- **${name}**: ${locations.length} definitions (${reason})\n`;
    }
    if (Object.keys(legitimateDuplicates).length > 10) {
      content += `- ... and ${Object.keys(legitimateDuplicates).length - 10} more\n`;
    }
    content += `\n`;
  }

  // Files in this report
  content += `## ðŸ“ Report Files\n\n`;
  content += `### Individual Duplication Reports\n`;
  for (const dupe of duplicationFiles) {
    content += `- [\`${dupe.name}\`](${dupe.filename}) (${dupe.count} definitions)\n`;
  }
  content += `\n`;

  content += `### Other Files\n`;
  if (Object.keys(ignored).length > 0) {
    content += `- [Ignored Auto-Generated Types](ignored-types.md)\n`;
  }
  if (Object.keys(legitimateDuplicates).length > 0) {
    content += `- [Legitimate Duplications](legitimate-duplications.md)\n`;
  }
  if (Object.keys(warningDuplicates).length > 0) {
    content += `- [Warning Duplications](warning-duplications.md) - concerning but not blocking\n`;
  }
  if (Object.keys(familyLegitimate).length > 0) {
    content += `- [Family Components](family-legitimate.md) - legitimate across families\n`;
  }
  content += `- [Fix Commands Script](fix-commands.sh)\n`;
  content += `- [Raw Data JSON](data.json)\n\n`;

  // Quick commands
  content += `## ðŸš€ Quick Actions\n\n`;
  content += `\`\`\`bash\n`;
  content += `# Apply all fix commands\n`;
  content += `bash fix-commands.sh\n\n`;
  content += `# Re-run analysis\n`;
  content += `node scripts/check-type-duplicates.cjs\n\n`;
  content += `# View specific duplication\n`;
  content += `# Choose from the files above\n`;
  content += `\`\`\`\n\n`;

  // Status and next steps
  if (stats.duplicateNames > 0) {
    content += `## ðŸŽ¯ Next Steps\n\n`;
    content += `1. **Review top duplications** (highest count first)\n`;
    content += `2. **Apply fix commands** for each duplication\n`;
    content += `3. **Test builds** after each fix\n`;
    content += `4. **Re-run analysis** to verify progress\n\n`;

    content += `**Priority Order:**\n`;
    for (const dupe of sortedDupes.slice(0, 5)) {
      content += `- [ ] [${dupe.name}](${dupe.filename}) (${dupe.count} definitions)\n`;
    }
  }

  // Suggestions for incremental updates
  content += enhanceSummaryWithUpdateSuggestions(duplicates);

  return content;
}

function determineCanonicalPackage(typeName, locations) {
  // Logic to determine the best canonical package for a type
  const _familyPatterns = {
    'supernal-coding': /@supernal-coding\/types/,
    'supernal-id': /@supernal-id\/types/,
    'platform-auth': /@supernal\/types-auth/,
    'platform-core': /@supernal\/types-core/,
    platform: /@supernal\/types/,
  };

  // Check if it's clearly family-specific
  const commandLocs = locations.filter((loc) =>
    loc.file.includes('supernal-coding')
  );
  const idLocs = locations.filter((loc) => loc.file.includes('supernal-id'));
  const _platformLocs = locations.filter((loc) =>
    loc.file.includes('platform')
  );

  if (commandLocs.length > 0 && idLocs.length === 0) {
    return '@supernal-coding/types';
  }
  if (idLocs.length > 0 && commandLocs.length === 0) {
    return '@supernal-id/types';
  }
  if (
    typeName.includes('Auth') ||
    typeName.includes('User') ||
    typeName.includes('Session')
  ) {
    return 'auth-types';
  }
  if (
    typeName.includes('Context') ||
    typeName.includes('Chrome') ||
    typeName.includes('Workspace')
  ) {
    return '@supernal-coding/types';
  }
  if (
    typeName.includes('Identity') ||
    typeName.includes('KYC') ||
    typeName.includes('Verification')
  ) {
    return '@supernal-id/types';
  }

  return 'local-types'; // Default to local types
}

function _calculateConfidenceScore(duplicates, stats) {
  if (stats.totalExports === 0) return 100;

  const duplicateRatio = Object.keys(duplicates).length / stats.totalExports;
  const confidence = Math.max(0, Math.round((1 - duplicateRatio) * 100));

  return confidence;
}

function generateReport(
  analysisData,
  isPreCommit = false,
  forceCommit = false
) {
  const {
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    stats,
  } = analysisData;

  console.log(`ðŸ“Š Analysis Results:`);
  console.log(`   Total exports found: ${stats.totalExports}`);
  console.log(`   Unique export names: ${stats.uniqueNames}`);
  console.log(
    `   ðŸš¨ Real duplications: ${stats.duplicateNames} names (${stats.duplicateInstances} instances)`
  );
  console.log(
    `   âš ï¸ Warning duplications: ${stats.warningNames || 0} names (${stats.warningInstances || 0} instances)`
  );
  console.log(
    `   ðŸ‘¥ Family components: ${stats.familyLegitimateNames || 0} names (${stats.familyLegitimateInstances || 0} instances)`
  );
  console.log(
    `   ðŸ” Legitimate duplications: ${stats.legitimateNames} names (${stats.legitimateInstances} instances)`
  );
  console.log(
    `   âœ… Ignored (auto-generated): ${stats.ignoredNames} names (${stats.ignoredInstances} instances)`
  );
  console.log('');

  // Write new structured files
  const result = writeResultsToFiles(
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    stats,
    analysisData.imports
  );

  if (stats.duplicateNames === 0) {
    console.log('ðŸŽ‰ No real type duplications found!');
    console.log(`ðŸ“„ Report: ${result.summaryPath}`);
    return 0;
  } else {
    console.log('ðŸ”´ Top Real Type Duplications:');
    console.log('');

    const sortedDuplicates = Object.entries(duplicates)
      .sort(([, a], [, b]) => b.length - a.length)
      .slice(0, 10);

    for (const [name, locations] of sortedDuplicates) {
      console.log(`   ${name} (${locations.length} definitions)`);
    }

    console.log('');
    console.log(`ðŸ“„ Detailed reports: ${result.baseDir}/`);
    console.log(`ðŸ“‹ Summary: ${result.summaryPath}`);

    if (isPreCommit && !forceCommit) {
      console.log('');
      console.log(
        'âŒ COMMIT BLOCKED - Fix real duplications before committing'
      );
      console.log(
        'ðŸ’¡ Review individual duplication files for specific fix instructions'
      );
      console.log(
        'ðŸ’¡ Use --force to commit anyway (e.g., when committing duplication tooling)'
      );
      return 1;
    }

    if (isPreCommit && forceCommit) {
      console.log('');
      console.log('âš ï¸  FORCE COMMIT - Allowing commit despite duplications');
      console.log(
        'ðŸ”§ This should only be used for committing duplication tooling or emergency fixes'
      );
    }

    return 0;
  }
}

// Check for .code.env bypass
function checkCodeEnvBypass() {
  const codeEnvPath = path.join(process.cwd(), '.code.env');

  if (!fs.existsSync(codeEnvPath)) {
    return { bypassed: false };
  }

  try {
    const envContent = fs.readFileSync(codeEnvPath, 'utf8');
    const lines = envContent.split('\n');

    for (const line of lines) {
      const trimmedLine = line.trim();
      if (trimmedLine.startsWith('DISABLE_TYPE_CHECKING=')) {
        const value = trimmedLine.split('=')[1];
        if (value === 'true' || value === '1' || value === 'yes') {
          return {
            bypassed: true,
            file: codeEnvPath,
            line: trimmedLine,
          };
        }
      }
    }

    return { bypassed: false };
  } catch (error) {
    console.warn(`âš ï¸  Could not read .code.env file: ${error.message}`);
    return { bypassed: false };
  }
}

function main() {
  const args = process.argv.slice(2);
  const isPreCommit = args.includes('--pre-commit');
  const showIgnored = args.includes('--show-ignored');
  const _showLegitimate = args.includes('--show-legitimate');
  const addIgnore = args.find((arg) => arg.startsWith('--add-ignore='));
  const addLegitimate = args.find((arg) => arg.startsWith('--add-legitimate='));
  const initConfig = args.includes('--init-config');
  const updateSpecific = args.find((arg) => arg.startsWith('--update='));
  const updateTypes = args.find((arg) => arg.startsWith('--update-types='));
  const showUsage = args.includes('--help') || args.includes('-h');
  const forceCommit = args.includes('--force');

  // Check for .code.env bypass FIRST
  const envBypass = checkCodeEnvBypass();
  if (envBypass.bypassed) {
    console.log('ðŸ”§ Type checking DISABLED via .code.env');
    console.log(`   Setting: ${envBypass.line}`);
    console.log(`   File: ${envBypass.file}`);
    console.log('');
    console.log('ðŸ’¡ To re-enable type checking:');
    console.log('   â€¢ Edit .code.env and set DISABLE_TYPE_CHECKING=false');
    console.log('   â€¢ Or delete the .code.env file');
    console.log('   â€¢ Or remove the DISABLE_TYPE_CHECKING line');
    console.log('');
    console.log('âœ… Bypassing type duplication check');
    return 0;
  }

  // Handle help/usage
  if (showUsage) {
    showUsageHelp();
    return 0;
  }

  // Handle config initialization
  if (initConfig) {
    createLintingConfig();
    return 0;
  }

  // Handle incremental updates
  if (updateSpecific) {
    const typeName = updateSpecific.split('=')[1];
    const success = updateSpecificDuplications([typeName]);
    return success ? 0 : 1;
  }

  if (updateTypes) {
    const typeNames = updateTypes
      .split('=')[1]
      .split(',')
      .map((name) => name.trim());
    const success = updateSpecificDuplications(typeNames);
    return success ? 0 : 1;
  }

  // Handle ignore list management
  if (addIgnore) {
    const typeName = addIgnore.split('=')[1];
    console.log(`Adding '${typeName}' to ignore list...`);
    console.log(
      `Add this to CONFIG.ignoreTypeNames in the script: '${typeName}',`
    );
    return 0;
  }

  // Handle legitimate duplication management
  if (addLegitimate) {
    const typeName = addLegitimate.split('=')[1];
    addToLegitimateConfig(typeName);
    return 0;
  }

  console.log(
    'ðŸ” Enhanced Duplication Checker: Types, Functions, Enums, Constants'
  );
  console.log('');

  const { exports: allExports, imports: allImports } = findAllExports();
  const {
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    stats,
  } = analyzeExports(allExports);

  // Add import analysis to the results for enhanced reporting
  const analysisData = {
    duplicates,
    ignored,
    legitimateDuplicates,
    warningDuplicates,
    familyLegitimate,
    stats,
    imports: allImports,
    exports: allExports,
    showIgnored,
  };

  const exitCode = generateReport(analysisData, isPreCommit, forceCommit);
  process.exit(exitCode);
}

if (require.main === module) {
  main();
}

module.exports = { findAllExports, analyzeExports };

// Load duplication lint configuration
function loadDuplicationLintConfig() {
  const configPath = path.join(process.cwd(), DUPLICATION_LINTING.configFile);

  let config = {
    ignoreTypes: [],
    ignoreFiles: [],
    legitDuplicationPatterns: DUPLICATION_LINTING.defaultLegitimatePatterns,
    customRules: {},
  };

  try {
    if (fs.existsSync(configPath)) {
      const userConfig = JSON.parse(fs.readFileSync(configPath, 'utf8'));
      config = { ...config, ...userConfig };
    }
  } catch (error) {
    console.warn(
      `âš ï¸  Could not load duplication lint config: ${error.message}`
    );
  }

  return config;
}

// Check if a duplication should be ignored based on linting rules
function shouldIgnoreDuplication(typeName, locations, lintConfig) {
  // 1. Check if type name is explicitly ignored
  if (lintConfig.ignoreTypes.includes(typeName)) {
    return { ignored: true, reason: 'explicitly ignored in config' };
  }

  // 2. Check family component patterns
  if (lintConfig.legitDuplicationPatterns.familyComponents.includes(typeName)) {
    const families = [
      ...new Set(
        locations.map(
          (loc) =>
            loc.file.split('/').find((part) => part.startsWith('supernal-')) ||
            'platform'
        )
      ),
    ];

    if (families.length > 1) {
      return {
        ignored: true,
        reason: `legitimate family component across: ${families.join(', ')}`,
      };
    }
  }

  // 3. Check utility patterns
  for (const pattern of lintConfig.legitDuplicationPatterns.utilityPatterns) {
    if (typeof pattern === 'string' && typeName === pattern) {
      return { ignored: true, reason: 'legitimate utility pattern' };
    }
    if (pattern instanceof RegExp && pattern.test(typeName)) {
      return { ignored: true, reason: `matches utility pattern: ${pattern}` };
    }
  }

  // 4. Check test patterns
  for (const pattern of lintConfig.legitDuplicationPatterns.testPatterns) {
    if (typeof pattern === 'string' && typeName === pattern) {
      return { ignored: true, reason: 'legitimate test utility' };
    }
    if (pattern instanceof RegExp && pattern.test(typeName)) {
      return { ignored: true, reason: `matches test pattern: ${pattern}` };
    }
  }

  // 5. Check config patterns
  for (const pattern of lintConfig.legitDuplicationPatterns.configPatterns) {
    if (typeName.toLowerCase().includes(pattern)) {
      return { ignored: true, reason: 'legitimate config pattern' };
    }
  }

  // 6. Check inline comments in source files
  for (const location of locations) {
    if (hasInlineIgnoreComment(location.file, location.line)) {
      return { ignored: true, reason: 'inline ignore comment' };
    }
  }

  // 7. Check file-level ignores
  for (const location of locations) {
    const shouldIgnoreFile = lintConfig.ignoreFiles.some((pattern) => {
      if (typeof pattern === 'string') {
        return location.file.includes(pattern);
      }
      if (pattern instanceof RegExp) {
        return pattern.test(location.file);
      }
      return false;
    });

    if (shouldIgnoreFile) {
      return { ignored: true, reason: 'file ignored in config' };
    }
  }

  return { ignored: false, reason: null };
}

// Check for ESLint-style duplication comments near the export
function checkInlineComment(filePath, lineNumber) {
  const result = {
    type: null, // 'ignore', 'warning', 'familyLegitimate', null
    reason: null, // extracted reason if available
    line: null, // line where comment was found
  };

  try {
    const content = fs.readFileSync(filePath, 'utf8');
    const lines = content.split('\n');

    // Check line before export, same line, and line after
    const checkLines = [
      lineNumber - 2,
      lineNumber - 1,
      lineNumber,
      lineNumber + 1,
    ].filter((line) => line >= 0 && line < lines.length);

    for (const lineIndex of checkLines) {
      const lineContent = lines[lineIndex];
      if (!lineContent) continue;

      // Check each comment type in priority order
      for (const [commentType, patterns] of Object.entries(
        DUPLICATION_LINTING.eslintStylePatterns
      )) {
        for (const pattern of patterns) {
          if (pattern.test(lineContent)) {
            result.type = commentType;
            result.line = lineIndex + 1; // Convert to 1-based line number

            // Extract reason from comment if available
            const reasonMatch = lineContent.match(
              /(?:reason[:\s]+|--\s+)(.+?)(?:\s*\*\/|\s*$)/i
            );
            if (reasonMatch) {
              result.reason = reasonMatch[1].trim();
            }

            return result;
          }
        }
      }
    }
  } catch (_error) {
    // File reading error, return no comment found
  }

  return result;
}

// Legacy function for backward compatibility
function hasInlineIgnoreComment(filePath, lineNumber) {
  const comment = checkInlineComment(filePath, lineNumber);
  return comment.type === 'ignore';
}

// Create initial linting configuration file
function createLintingConfig() {
  const configPath = path.join(process.cwd(), DUPLICATION_LINTING.configFile);

  if (fs.existsSync(configPath)) {
    console.log(`âš ï¸  Configuration file already exists: ${configPath}`);
    console.log(
      'Add new rules manually or delete and re-run with --init-config'
    );
    return;
  }

  const defaultConfig = {
    // Explicitly ignored type names (these are completely hidden from reports)
    ignoreTypes: [
      // Add specific type names here
      // "SpecificTypeName"
    ],

    // Ignored file patterns (duplications in these files are hidden)
    ignoreFiles: ['test/', 'spec/', '.test.', '.spec.', 'fixtures/', 'mock'],

    // Legitimate duplication patterns (shown in reports but marked as OK)
    legitDuplicationPatterns: {
      // Family-specific components that are OK to duplicate across families
      familyComponents: [
        'HeroSection',
        'Header',
        'Footer',
        'Layout',
        'Navigation',
        'Sidebar',
        'MainContent',
        'AboutSection',
        'ContactForm',
        'FeatureCard',
        'TestimonialCard',
        'PricingCard',
      ],

      // Cross-family utilities that are OK to duplicate
      utilityPatterns: [
        // React hooks (different contexts)
        '^use[A-Z]',
        // Factory functions (different services)
        '^create[A-Z]',
        // Getters (different contexts)
        '^get[A-Z]',
        // Formatters
        '^format[A-Z]',
        // Validation
        '^validate[A-Z]',
        // Normalization
        '^normalize[A-Z]',
        // Common utilities
        'cn',
        'clsx',
        'metadata',
      ],

      // Development/test utilities
      testPatterns: ['Test$', 'Mock$', 'Fixture$', 'Stub$', 'logger'],

      // Configuration objects
      configPatterns: ['config', 'settings', 'options', 'constants'],
    },

    // Custom rules for specific patterns
    customRules: {
      // Example: "ruleName": { "pattern": "regex", "reason": "explanation" }
    },
  };

  fs.writeFileSync(configPath, JSON.stringify(defaultConfig, null, 2));
  console.log(`âœ… Created duplication linting config: ${configPath}`);
  console.log('');
  console.log('ðŸ“ Edit this file to configure legitimate duplications');
  console.log('');
  console.log('Example usage:');
  console.log(
    '  node scripts/check-type-duplicates.cjs                    # Run analysis'
  );
  console.log(
    '  node scripts/check-type-duplicates.cjs --add-legitimate=HeroSection  # Mark as legitimate'
  );
  console.log(
    '  node scripts/check-type-duplicates.cjs --show-legitimate  # Show legitimate only'
  );
}

// Add a type to the legitimate duplications config
function addToLegitimateConfig(typeName) {
  const configPath = path.join(process.cwd(), DUPLICATION_LINTING.configFile);

  let config;
  try {
    if (fs.existsSync(configPath)) {
      config = JSON.parse(fs.readFileSync(configPath, 'utf8'));
    } else {
      console.log('âš ï¸  No config file found. Run --init-config first.');
      return;
    }
  } catch (error) {
    console.log(`âŒ Error reading config: ${error.message}`);
    return;
  }

  // Add to family components (most common case)
  if (!config.legitDuplicationPatterns.familyComponents.includes(typeName)) {
    config.legitDuplicationPatterns.familyComponents.push(typeName);

    try {
      fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
      console.log(`âœ… Added '${typeName}' to legitimate family components`);
      console.log(`ðŸ“„ Updated: ${configPath}`);
    } catch (error) {
      console.log(`âŒ Error writing config: ${error.message}`);
    }
  } else {
    console.log(`â„¹ï¸  '${typeName}' is already marked as legitimate`);
  }
}

// Generate report for legitimate duplications
function generateLegitimateTypesReport(legitimateDuplicates, _stats) {
  let content = `# Legitimate Duplications Report\n\n`;
  content += `These duplications are marked as legitimate and OK to exist.\n\n`;
  content += `**Total:** ${Object.keys(legitimateDuplicates).length} types (${Object.values(legitimateDuplicates).reduce((sum, item) => sum + item.locations.length, 0)} instances)\n\n`;

  // Group by reason
  const byReason = {};
  for (const [name, { locations, reason }] of Object.entries(
    legitimateDuplicates
  )) {
    if (!byReason[reason]) {
      byReason[reason] = [];
    }
    byReason[reason].push({ name, locations });
  }

  for (const [reason, types] of Object.entries(byReason)) {
    content += `## ${reason}\n\n`;

    types.sort((a, b) => b.locations.length - a.locations.length);

    for (const { name, locations } of types) {
      content += `### ${name} (${locations.length} definitions)\n\n`;

      for (const location of locations) {
        content += `- **${path.basename(location.file)}**: \`${location.file}:${location.line}\`\n`;
      }
      content += '\n';
    }
  }

  content += `## Configuration\n\n`;
  content += `These duplications are marked as legitimate in \`.duplication-lint.json\`.\n\n`;
  content += `To remove from legitimate list:\n`;
  content += `1. Edit \`.duplication-lint.json\`\n`;
  content += `2. Remove the type name or pattern\n`;
  content += `3. Re-run analysis\n\n`;

  return content;
}

// Generate warning duplications report
function generateWarningTypesReport(warningDuplicates, _stats) {
  let content = `# Warning Duplications Report\n\n`;
  content += `**Count:** ${Object.keys(warningDuplicates).length} types\n`;
  content += `**Status:** Concerning but not blocking\n\n`;
  content += `These duplications have been marked with warning comments (e.g., \`// eslint-disable-next-line duplication/concerning\`) indicating they are concerning patterns but should not block builds or commits.\n\n`;

  for (const [name, { locations, reason }] of Object.entries(
    warningDuplicates
  )) {
    content += `## ${name}\n`;
    content += `**Reason:** ${reason}\n`;
    content += `**Locations:** ${locations.length}\n\n`;

    for (const location of locations) {
      content += `- **${path.basename(location.file)}:${location.line}** (${location.type})\n`;
      content += `  \`${location.file}\`\n`;
    }
    content += `\n`;
  }

  content += `## How to Handle Warning Duplications\n\n`;
  content += `1. **Review the pattern** - Is this duplication necessary?\n`;
  content += `2. **Document the decision** - Add more detailed comments explaining why\n`;
  content += `3. **Monitor for growth** - Ensure the pattern doesn't spread unnecessarily\n`;
  content += `4. **Consider consolidation** - Could these be unified in the future?\n\n`;
  content += `## Comment Examples\n\n`;
  content += `\`\`\`typescript\n`;
  content += `// eslint-disable-next-line duplication/concerning -- TestPattern: Used in multiple test files\n`;
  content += `export interface TestProps {\n`;
  content += `  // ...\n`;
  content += `}\n`;
  content += `\`\`\`\n`;

  return content;
}

// Generate family legitimate duplications report
function generateFamilyLegitimateReport(familyLegitimate, _stats) {
  let content = `# Family Component Duplications Report\n\n`;
  content += `**Count:** ${Object.keys(familyLegitimate).length} types\n`;
  content += `**Status:** Legitimate across family boundaries\n\n`;
  content += `These duplications have been marked as legitimate family-specific components (e.g., \`// eslint-disable-next-line duplication/family-component\`) that are expected to exist in multiple families.\n\n`;

  for (const [name, { locations, reason }] of Object.entries(
    familyLegitimate
  )) {
    content += `## ${name}\n`;
    content += `**Reason:** ${reason}\n`;
    content += `**Families:** ${locations.length}\n\n`;

    // Group by family
    const byFamily = {};
    for (const location of locations) {
      const family = location.file.includes('supernal-coding')
        ? 'supernal-coding'
        : location.file.includes('supernal-id')
          ? 'supernal-id'
          : location.file.includes('supernal-web')
            ? 'supernal-web'
            : 'platform';
      if (!byFamily[family]) byFamily[family] = [];
      byFamily[family].push(location);
    }

    for (const [family, locs] of Object.entries(byFamily)) {
      content += `### ${family}\n`;
      for (const location of locs) {
        content += `- **${path.basename(location.file)}:${location.line}** (${location.type})\n`;
        content += `  \`${location.file}\`\n`;
      }
      content += `\n`;
    }
  }

  content += `## Family Component Guidelines\n\n`;
  content += `1. **Each family owns its version** - Don't try to unify across families\n`;
  content += `2. **Maintain consistency within family** - Use the same component across the family\n`;
  content += `3. **Document differences** - If families need different props, document why\n`;
  content += `4. **Consider extraction** - Could shared logic be extracted to a platform package?\n\n`;
  content += `## Comment Examples\n\n`;
  content += `\`\`\`typescript\n`;
  content += `// eslint-disable-next-line duplication/family-component -- Each family needs its own HeroSection\n`;
  content += `export const HeroSection: React.FC<HeroProps> = ({ title, subtitle }) => {\n`;
  content += `  // Family-specific implementation\n`;
  content += `};\n`;
  content += `\`\`\`\n`;

  return content;
}

// Generate ESLint-style comment suggestions for a duplication
function generateESLintSuggestions(name, locations) {
  let content = `## ðŸ”§ ESLint-Style Comment Solutions\n\n`;

  const _isComponent =
    name.includes('Component') ||
    name.includes('Section') ||
    name.includes('Form') ||
    name.includes('Button');
  const isTest =
    name.includes('Test') || name.includes('Mock') || name.includes('Fixture');
  const isUtil =
    name.includes('util') ||
    name.includes('helper') ||
    name.includes('config') ||
    name.startsWith('use') ||
    name.startsWith('create');
  const familyCount = countFamiliesInLocations(locations);

  content += `**Quick Decision Guide:**\n`;
  if (familyCount > 1) {
    content += `- ðŸ‘¥ **Family Component** (${familyCount} families) - Each family needs its own version\n`;
  }
  if (isTest) {
    content += `- âš ï¸ **Test Pattern** - Concerning but not blocking\n`;
  }
  if (isUtil) {
    content += `- ðŸ” **Utility Pattern** - Legitimate if package independence needed\n`;
  }
  content += `- ðŸš¨ **Real Duplication** - Needs consolidation\n\n`;

  content += `### Option 1: Family Component (if spans families)\n`;
  content += `\`\`\`bash\n`;
  for (const location of locations) {
    content += `# Add to ${location.file} around line ${location.line}\n`;
    content += `sed -i '${location.line - 1}i\\// eslint-disable-next-line duplication/family-component' "${location.file}"\n`;
  }
  content += `\`\`\`\n\n`;

  content += `### Option 2: Test Pattern (if test utilities)\n`;
  content += `\`\`\`bash\n`;
  for (const location of locations) {
    content += `# Add to ${location.file} around line ${location.line}\n`;
    content += `sed -i '${location.line - 1}i\\// eslint-disable-next-line duplication/concerning -- TestPattern: Shared across test files' "${location.file}"\n`;
  }
  content += `\`\`\`\n\n`;

  content += `### Option 3: Legitimate Duplication (if package independence needed)\n`;
  content += `\`\`\`bash\n`;
  for (const location of locations) {
    content += `# Add to ${location.file} around line ${location.line}\n`;
    content += `sed -i '${location.line - 1}i\\// eslint-disable-next-line duplication/legitimate -- Package independence required for ${name}' "${location.file}"\n`;
  }
  content += `\`\`\`\n\n`;

  content += `### Option 4: Manual Comment Addition\n`;
  content += `Add one of these comments directly before each export:\n\n`;
  content += `\`\`\`typescript\n`;
  content += `// eslint-disable-next-line duplication/family-component -- reason here\n`;
  content += `// eslint-disable-next-line duplication/concerning -- reason here\n`;
  content += `// eslint-disable-next-line duplication/legitimate -- reason here\n`;
  content += `export ${locations[0]?.type || 'interface'} ${name} {\n`;
  content += `  // ...\n`;
  content += `}\n`;
  content += `\`\`\`\n\n`;

  return content;
}

// Count how many different families are represented in locations
function countFamiliesInLocations(locations) {
  const families = new Set();
  for (const location of locations) {
    if (location.file.includes('supernal-coding'))
      families.add('supernal-coding');
    else if (location.file.includes('supernal-id')) families.add('supernal-id');
    else if (location.file.includes('supernal-web'))
      families.add('supernal-web');
    else if (location.file.includes('supernal-kids'))
      families.add('supernal-kids');
    else if (location.file.includes('platform')) families.add('platform');
  }
  return families.size;
}

// Generate file-specific ESLint command for individual locations
function generateFileSpecificESLintCommand(location, _name) {
  let content = `#### ðŸ’¡ Add ESLint Comment:\n`;
  content += `\`\`\`bash\n`;
  content += `# Quick family component marking:\n`;
  content += `sed -i '${location.line - 1}i\\// eslint-disable-next-line duplication/family-component' "${location.file}"\n\n`;
  content += `# Quick legitimate marking:\n`;
  content += `sed -i '${location.line - 1}i\\// eslint-disable-next-line duplication/legitimate' "${location.file}"\n\n`;
  content += `# Quick test pattern marking:\n`;
  content += `sed -i '${location.line - 1}i\\// eslint-disable-next-line duplication/concerning' "${location.file}"\n`;
  content += `\`\`\`\n\n`;
  return content;
}

// Update specific duplication files (incremental updates)
function updateSpecificDuplications(typeNames, baseDir = null) {
  if (!baseDir) {
    const latestPath = 'reports/duplications/latest';
    if (!fs.existsSync(latestPath)) {
      console.log('âŒ No existing reports found. Run full analysis first.');
      return false;
    }
    baseDir = fs.readlinkSync(latestPath);
    baseDir = `reports/duplications/${baseDir}`;
  }

  console.log(`ðŸ”„ Updating specific duplications in ${baseDir}`);

  // Load existing data
  const dataPath = `${baseDir}/data.json`;
  if (!fs.existsSync(dataPath)) {
    console.log('âŒ No data.json found. Cannot perform incremental update.');
    return false;
  }

  const data = JSON.parse(fs.readFileSync(dataPath, 'utf8'));
  let updated = 0;

  for (const typeName of typeNames) {
    if (data.duplicates[typeName]) {
      console.log(`ðŸ“ Updating ${typeName}...`);

      const filename = `${typeName.replace(/[^a-zA-Z0-9]/g, '_')}.md`;
      const filePath = `${baseDir}/${filename}`;

      const content = generateDuplicationReport(
        typeName,
        data.duplicates[typeName],
        data.imports[typeName] || []
      );

      fs.writeFileSync(filePath, content);
      updated++;
    } else {
      console.log(`âš ï¸ ${typeName} not found in duplications data`);
    }
  }

  console.log(`âœ… Updated ${updated} duplication files`);
  return true;
}

// Show usage help and examples
function showUsageHelp() {
  console.log(`
ðŸ” Enhanced Type Duplication Checker

USAGE:
  node scripts/check-type-duplicates.cjs [OPTIONS]

OPTIONS:
  --help, -h                Show this help message
  --pre-commit              Run in pre-commit mode (exit with error on duplications)
  --force                   Force commit despite duplications (use with --pre-commit)
  --show-ignored            Include ignored types in output
  --show-legitimate         Include legitimate duplications in output
  --init-config             Create initial .duplication-lint.json config file
  
  # Configuration Management:
  --add-ignore=TYPE         Add a type to the ignore list
  --add-legitimate=TYPE     Add a type to legitimate duplications
  
  # Incremental Updates (faster for specific fixes):
  --update=TYPE_NAME        Update only the specified type's report
  --update-types=TYPE1,TYPE2,TYPE3  Update multiple specific types
  
EXAMPLES:
  # Full analysis (generates all reports)
  node scripts/check-type-duplicates.cjs
  
  # Pre-commit check (fail on real duplications)
  node scripts/check-type-duplicates.cjs --pre-commit
  
  # Force commit despite duplications (for tooling commits)
  node scripts/check-type-duplicates.cjs --pre-commit --force
  
  # Update specific type after adding ESLint comment
  node scripts/check-type-duplicates.cjs --update=WaitlistForm
  
  # Update multiple types at once
  node scripts/check-type-duplicates.cjs --update-types=WaitlistForm,HeroSection,Button
  
  # Initialize configuration
  node scripts/check-type-duplicates.cjs --init-config
  
  # Add type to legitimate duplications
  node scripts/check-type-duplicates.cjs --add-legitimate=HeroSection

WORKFLOW TIPS:
  1. Run full analysis first to identify all duplications
  2. Review individual markdown files in reports/duplications/latest/
  3. Use ESLint-style comments to mark legitimate duplications
  4. Use --update= to refresh specific types after changes
  5. Run --pre-commit before committing to verify all are handled

REPORT LOCATIONS:
  reports/duplications/latest/README.md     # Summary
  reports/duplications/latest/*.md          # Individual type reports
  reports/duplications/latest/data.json     # Raw data for tools
`);
}

// Add suggestion for incremental updates to the summary report
function enhanceSummaryWithUpdateSuggestions(duplicates) {
  const topDuplicates = Object.entries(duplicates)
    .sort(([, a], [, b]) => b.length - a.length)
    .slice(0, 10)
    .map(([name]) => name);

  if (topDuplicates.length === 0) return '';

  let content = `\n## ðŸ”„ Quick Update Commands\n\n`;
  content += `After adding ESLint comments to fix duplications, use these commands for quick updates:\n\n`;
  content += `\`\`\`bash\n`;
  content += `# Update individual types:\n`;
  for (const typeName of topDuplicates.slice(0, 5)) {
    content += `node scripts/check-type-duplicates.cjs --update=${typeName}\n`;
  }
  content += `\n# Update multiple types at once:\n`;
  content += `node scripts/check-type-duplicates.cjs --update-types=${topDuplicates.slice(0, 5).join(',')}\n`;
  content += `\n# Re-run full analysis:\n`;
  content += `node scripts/check-type-duplicates.cjs\n`;
  content += `\`\`\`\n\n`;

  return content;
}
